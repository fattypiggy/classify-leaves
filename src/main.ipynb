{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T02:40:41.736378Z",
     "start_time": "2024-11-07T02:40:39.362115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# main.ipynb\n",
    "\n",
    "# 导入必要的库\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 检查是否可以使用MPS（Metal Performance Shaders）进行GPU加速\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f'使用设备: {device}')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamjing/opt/anaconda3/envs/kaggle/lib/python3.9/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/williamjing/opt/anaconda3/envs/kaggle/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <FB2FD416-6C4D-3621-B677-61F07C02A3C5> /Users/williamjing/opt/anaconda3/envs/kaggle/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/williamjing/opt/anaconda3/envs/kaggle/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/williamjing/opt/anaconda3/envs/kaggle/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/williamjing/opt/anaconda3/envs/kaggle/lib/python3.9/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/williamjing/opt/anaconda3/envs/kaggle/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: mps\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T02:40:41.744229Z",
     "start_time": "2024-11-07T02:40:41.740812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据预处理和增强\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],   # ImageNet的均值和标准差\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],   # ImageNet的均值和标准差\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T02:40:41.832965Z",
     "start_time": "2024-11-07T02:40:41.829370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 自定义数据集类\n",
    "class LeafDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, mode='train'):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.mode = mode  # 'train' or 'test'\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            # 提取标签并进行编码\n",
    "            self.le = LabelEncoder()\n",
    "            self.data['label'] = self.le.fit_transform(self.data['label'])\n",
    "            self.classes = self.le.classes_\n",
    "        else:\n",
    "            self.classes = None  # 测试集没有标签\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join('..', self.data.iloc[idx, 0])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            label = self.data.iloc[idx, 1]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, self.data.iloc[idx, 0]  # 返回图像和文件名\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T02:40:41.852196Z",
     "start_time": "2024-11-07T02:40:41.837835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载训练数据集\n",
    "train_csv = '../train.csv'  # 请根据实际情况调整路径\n",
    "train_dataset = LeafDataset(csv_file=train_csv, transform=data_transforms['train'], mode='train')\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(f'类别数量: {num_classes}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别数量: 176\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T02:40:41.859343Z",
     "start_time": "2024-11-07T02:40:41.856905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 准备K折交叉验证\n",
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# 训练参数\n",
    "num_epochs = 25\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T02:40:41.871182Z",
     "start_time": "2024-11-07T02:40:41.866058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义训练和验证函数\n",
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs, fold):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Fold {fold}, Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 每个epoch都有训练和验证阶段\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # 设置模型为训练模式\n",
    "            else:\n",
    "                model.eval()   # 设置模型为评估模式\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 遍历数据\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 清零参数梯度\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 前向传播\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # 训练阶段反向传播+优化\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 统计\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # 学习率调整\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # 计算损失和准确率\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # 深拷贝模型\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Fold {fold} 训练完成于 {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'最佳验证准确率: {best_acc:.4f}')\n",
    "\n",
    "    # 加载最佳模型权重\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T03:11:57.263250Z",
     "start_time": "2024-11-07T02:40:41.881343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 开始K折交叉验证\n",
    "fold_results = {}\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n",
    "    print(f'Fold {fold}')\n",
    "    print('-' * 20)\n",
    "\n",
    "    # 创建数据子集\n",
    "    train_subsampler = Subset(train_dataset, train_idx)\n",
    "    val_subsampler = Subset(train_dataset, val_idx)\n",
    "\n",
    "    # 数据加载器\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(train_subsampler, batch_size=batch_size, shuffle=True),\n",
    "        'val': DataLoader(val_subsampler, batch_size=batch_size, shuffle=False)\n",
    "    }\n",
    "\n",
    "    # 初始化模型\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    # 修改最后的全连接层\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 设置优化器和学习率调度器\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    # 每7个epoch学习率降低0.1倍\n",
    "    exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    # 训练和评估\n",
    "    model, best_acc = train_model(model, dataloaders, criterion, optimizer, exp_lr_scheduler, num_epochs, fold)\n",
    "\n",
    "    # 保存每个fold的最佳模型\n",
    "    torch.save(model.state_dict(), f'model_fold_{fold}.pth')\n",
    "\n",
    "    # 存储结果\n",
    "    fold_results[fold] = {'model': model, 'best_acc': best_acc}\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamjing/opt/anaconda3/envs/kaggle/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/williamjing/opt/anaconda3/envs/kaggle/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0, Epoch 0/24\n",
      "----------\n",
      "Train Loss: 3.8880 Acc: 0.2087\n",
      "Val Loss: 2.5578 Acc: 0.4315\n",
      "\n",
      "Fold 0, Epoch 1/24\n",
      "----------\n",
      "Train Loss: 2.1098 Acc: 0.5214\n",
      "Val Loss: 1.6132 Acc: 0.6012\n",
      "\n",
      "Fold 0, Epoch 2/24\n",
      "----------\n",
      "Train Loss: 1.4136 Acc: 0.6746\n",
      "Val Loss: 1.1402 Acc: 0.7126\n",
      "\n",
      "Fold 0, Epoch 3/24\n",
      "----------\n",
      "Train Loss: 1.0270 Acc: 0.7680\n",
      "Val Loss: 0.9042 Acc: 0.7671\n",
      "\n",
      "Fold 0, Epoch 4/24\n",
      "----------\n",
      "Train Loss: 0.7926 Acc: 0.8192\n",
      "Val Loss: 0.7302 Acc: 0.8107\n",
      "\n",
      "Fold 0, Epoch 5/24\n",
      "----------\n",
      "Train Loss: 0.6285 Acc: 0.8560\n",
      "Val Loss: 0.5704 Acc: 0.8515\n",
      "\n",
      "Fold 0, Epoch 6/24\n",
      "----------\n",
      "Train Loss: 0.5087 Acc: 0.8835\n",
      "Val Loss: 0.5023 Acc: 0.8687\n",
      "\n",
      "Fold 0, Epoch 7/24\n",
      "----------\n",
      "Train Loss: 0.4028 Acc: 0.9198\n",
      "Val Loss: 0.4443 Acc: 0.8905\n",
      "\n",
      "Fold 0, Epoch 8/24\n",
      "----------\n",
      "Train Loss: 0.3856 Acc: 0.9209\n",
      "Val Loss: 0.4352 Acc: 0.8905\n",
      "\n",
      "Fold 0, Epoch 9/24\n",
      "----------\n",
      "Train Loss: 0.3737 Acc: 0.9280\n",
      "Val Loss: 0.4354 Acc: 0.8867\n",
      "\n",
      "Fold 0, Epoch 10/24\n",
      "----------\n",
      "Train Loss: 0.3606 Acc: 0.9303\n",
      "Val Loss: 0.4253 Acc: 0.8913\n",
      "\n",
      "Fold 0, Epoch 11/24\n",
      "----------\n",
      "Train Loss: 0.3559 Acc: 0.9307\n",
      "Val Loss: 0.4246 Acc: 0.8899\n",
      "\n",
      "Fold 0, Epoch 12/24\n",
      "----------\n",
      "Train Loss: 0.3489 Acc: 0.9320\n",
      "Val Loss: 0.4104 Acc: 0.8919\n",
      "\n",
      "Fold 0, Epoch 13/24\n",
      "----------\n",
      "Train Loss: 0.3379 Acc: 0.9390\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 32\u001B[0m\n\u001B[1;32m     29\u001B[0m exp_lr_scheduler \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mStepLR(optimizer, step_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m7\u001B[39m, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# 训练和评估\u001B[39;00m\n\u001B[0;32m---> 32\u001B[0m model, best_acc \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexp_lr_scheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfold\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# 保存每个fold的最佳模型\u001B[39;00m\n\u001B[1;32m     35\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_fold_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfold\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[6], line 23\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, dataloaders, criterion, optimizer, scheduler, num_epochs, fold)\u001B[0m\n\u001B[1;32m     20\u001B[0m running_corrects \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# 遍历数据\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m dataloaders[phase]:\n\u001B[1;32m     24\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     25\u001B[0m     labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.9/site-packages/torch/utils/data/dataloader.py:719\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    713\u001B[0m         warn_msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    714\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFor multiprocessing data-loading, this could be caused by not properly configuring the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    715\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIterableDataset replica at each worker. Please see \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    716\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    717\u001B[0m         )\n\u001B[1;32m    718\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(warn_msg)\n\u001B[0;32m--> 719\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.9/site-packages/torch/autograd/profiler.py:750\u001B[0m, in \u001B[0;36mrecord_function.__exit__\u001B[0;34m(self, exc_type, exc_value, traceback)\u001B[0m\n\u001B[1;32m    748\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_scripting():\n\u001B[1;32m    749\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39mDisableTorchFunctionSubclass():\n\u001B[0;32m--> 750\u001B[0m         \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprofiler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_record_function_exit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_RecordFunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    751\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    752\u001B[0m     torch\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39m_record_function_exit(record)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.9/site-packages/torch/_ops.py:940\u001B[0m, in \u001B[0;36mTorchBindOpOverload.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    939\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m/\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 940\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43m_must_dispatch_in_python\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    941\u001B[0m         \u001B[38;5;66;03m# When any inputs are FakeScriptObject, we need to\u001B[39;00m\n\u001B[1;32m    942\u001B[0m         \u001B[38;5;66;03m# skip c++ dispatcher and dispatch in python through _get_dispatch of python_dispatcher\u001B[39;00m\n\u001B[1;32m    943\u001B[0m         \u001B[38;5;66;03m# because C++ dispatcher will check the schema and cannot recognize FakeScriptObject.\u001B[39;00m\n\u001B[1;32m    944\u001B[0m         \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m    945\u001B[0m         \u001B[38;5;66;03m# Note:\u001B[39;00m\n\u001B[1;32m    946\u001B[0m         \u001B[38;5;66;03m# 1. We only register the torchbind op temporarily as effectful op because we only want\u001B[39;00m\n\u001B[1;32m    947\u001B[0m         \u001B[38;5;66;03m#    the effect token functionalization logic to be applied during tracing. Otherwise, the behavior\u001B[39;00m\n\u001B[1;32m    948\u001B[0m         \u001B[38;5;66;03m#    of the eagerly executing the op might change after tracing.\u001B[39;00m\n\u001B[1;32m    949\u001B[0m         \u001B[38;5;66;03m# 2. We don't want to register the op as effectful for all torchbind ops in ctor because this might\u001B[39;00m\n\u001B[1;32m    950\u001B[0m         \u001B[38;5;66;03m#    cause unexpected behavior for some autograd.profiler ops e.g. profiler._record_function_exit._RecordFunction.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_register_as_effectful_op_temporarily():\n\u001B[1;32m    952\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dispatch_in_python(args, kwargs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fallthrough_keys())\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.9/site-packages/torch/_ops.py:994\u001B[0m, in \u001B[0;36m_must_dispatch_in_python\u001B[0;34m(args, kwargs)\u001B[0m\n\u001B[1;32m    993\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_must_dispatch_in_python\u001B[39m(args, kwargs):\n\u001B[0;32m--> 994\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpytree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_any\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    995\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    996\u001B[0m \u001B[43m            \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_library\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfake_class_registry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFakeScriptObject\u001B[49m\n\u001B[1;32m    997\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    998\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    999\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/kaggle/lib/python3.9/site-packages/torch/utils/_pytree.py:1203\u001B[0m, in \u001B[0;36mtree_any\u001B[0;34m(pred, tree, is_leaf)\u001B[0m\n\u001B[1;32m   1197\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtree_any\u001B[39m(\n\u001B[1;32m   1198\u001B[0m     pred: Callable[[Any], \u001B[38;5;28mbool\u001B[39m],\n\u001B[1;32m   1199\u001B[0m     tree: PyTree,\n\u001B[1;32m   1200\u001B[0m     is_leaf: Optional[Callable[[PyTree], \u001B[38;5;28mbool\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1201\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[1;32m   1202\u001B[0m     flat_args \u001B[38;5;241m=\u001B[39m tree_iter(tree, is_leaf\u001B[38;5;241m=\u001B[39mis_leaf)\n\u001B[0;32m-> 1203\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_args\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 所有fold训练完成\n",
    "print('所有fold训练完成。')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 选择最佳模型\n",
    "best_fold = max(fold_results, key=lambda x: fold_results[x]['best_acc'])\n",
    "best_model = fold_results[best_fold]['model']\n",
    "print(f'最佳模型来自于Fold {best_fold}，验证准确率为{fold_results[best_fold][\"best_acc\"]:.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 加载测试集\n",
    "test_csv = '../test.csv'  # 请根据实际情况调整路径\n",
    "test_dataset = LeafDataset(csv_file=test_csv, transform=data_transforms['test'], mode='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 使用最佳模型进行预测\n",
    "best_model.eval()\n",
    "all_preds = []\n",
    "image_names = []\n",
    "with torch.no_grad():\n",
    "    for inputs, img_paths in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = best_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        image_names.extend(img_paths)\n",
    "\n",
    "# 将预测的标签整数映射回原始标签\n",
    "label_encoder = train_dataset.le  # 从训练集获取LabelEncoder\n",
    "predicted_labels = label_encoder.inverse_transform(all_preds)\n",
    "\n",
    "# 创建提交文件\n",
    "submission = pd.DataFrame({\n",
    "    'image': image_names,\n",
    "    'label': predicted_labels\n",
    "})\n",
    "\n",
    "# 保存为CSV文件\n",
    "submission.to_csv('sample_submission.csv', index=False)\n",
    "print('预测结果已保存到sample_submission.csv')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
